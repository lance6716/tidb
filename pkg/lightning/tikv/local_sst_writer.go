// Copyright 2024 PingCAP, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package tikv

import (
	"context"
	"encoding/binary"

	"github.com/google/uuid"
	rocks "github.com/lance6716/pebble"
	rocksbloom "github.com/lance6716/pebble/bloom"
	"github.com/lance6716/pebble/objstorage/objstorageprovider"
	rockssst "github.com/lance6716/pebble/sstable"
	"github.com/lance6716/pebble/vfs"
	"github.com/pingcap/errors"
	"github.com/pingcap/kvproto/pkg/import_sstpb"
	"github.com/pingcap/kvproto/pkg/kvrpcpb"
	"github.com/pingcap/tidb/pkg/util/codec"
	"github.com/pingcap/tidb/pkg/util/intest"
	pd "github.com/tikv/pd/client"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
)

// write2ImportService4Test writes these sorted key-value pairs to the TiKV
// cluster. SST files are generated by TiKV and saved in import directory if no
// error happens.
func write2ImportService4Test(
	ctx context.Context,
	pdAddrs []string,
	sortedKVs [][2][]byte,
	ts uint64,
) ([]*import_sstpb.SSTMeta, error) {
	pdClient, err := pd.NewClient(pdAddrs, pd.SecurityOption{})
	if err != nil {
		return nil, errors.Trace(err)
	}
	defer pdClient.Close()

	r0, err := pdClient.GetRegion(ctx, sortedKVs[0][0])
	if err != nil {
		return nil, errors.Trace(err)
	}
	r1, err := pdClient.GetRegion(ctx, sortedKVs[len(sortedKVs)-1][0])
	if err != nil {
		return nil, errors.Trace(err)
	}
	if r0.Meta.Id != r1.Meta.Id {
		return nil, errors.Errorf(
			"only support write to the same region, "+
				"first key: %X, last key: %X, "+
				"first region id: %d, last region id: %d",
			sortedKVs[0][0], sortedKVs[len(sortedKVs)-1][0],
			r0.Meta.Id, r1.Meta.Id,
		)
	}

	store, err := pdClient.GetStore(ctx, r0.Leader.GetStoreId())
	if err != nil {
		return nil, errors.Trace(err)
	}
	conn, err := grpc.DialContext(
		ctx, store.GetAddress(),
		grpc.WithTransportCredentials(insecure.NewCredentials()),
		grpc.WithBlock(),
	)
	if err != nil {
		return nil, errors.Trace(err)
	}
	defer conn.Close()

	ingestClient := import_sstpb.NewImportSSTClient(conn)
	writeStream, err := ingestClient.Write(ctx)
	if err != nil {
		return nil, errors.Trace(err)
	}
	u := uuid.New()
	writeMeta := &import_sstpb.SSTMeta{
		Uuid:        u[:],
		RegionId:    r0.Meta.Id,
		RegionEpoch: r0.Meta.RegionEpoch,
		Range: &import_sstpb.Range{
			Start: sortedKVs[0][0],
			End:   sortedKVs[len(sortedKVs)-1][0],
		},
	}
	rpcCtx := kvrpcpb.Context{
		RegionId:    r0.Meta.Id,
		RegionEpoch: r0.Meta.RegionEpoch,
		Peer:        r0.Leader,
	}
	err = writeStream.Send(&import_sstpb.WriteRequest{
		Chunk:   &import_sstpb.WriteRequest_Meta{Meta: writeMeta},
		Context: &rpcCtx,
	})
	if err != nil {
		return nil, errors.Trace(err)
	}

	batch := &import_sstpb.WriteBatch{
		CommitTs: ts,
		Pairs:    make([]*import_sstpb.Pair, 0, len(sortedKVs)),
	}
	for _, kv := range sortedKVs {
		batch.Pairs = append(batch.Pairs, &import_sstpb.Pair{
			Key:   kv[0],
			Value: kv[1],
		})
	}
	err = writeStream.Send(&import_sstpb.WriteRequest{
		Chunk:   &import_sstpb.WriteRequest_Batch{Batch: batch},
		Context: &rpcCtx,
	})
	if err != nil {
		return nil, errors.Trace(err)
	}
	resp, err := writeStream.CloseAndRecv()
	if err != nil {
		return nil, errors.Trace(err)
	}
	if resp.GetError() != nil {
		return nil, errors.Errorf("write failed: %s", resp.GetError())
	}
	return resp.Metas, nil
}

// writeCFWriter generates SST files for TiKV's write column family.
type writeCFWriter struct {
	sstWriter *rockssst.Writer
	ts        uint64
}

// newWriteCFWriter creates a new writeCFWriter. Currently `identity` is acquired
// from a real SST file generated by TiKV.
func newWriteCFWriter(
	sstPath string,
	ts uint64,
	identity *rockssst.Identity,
) (*writeCFWriter, error) {
	f, err := vfs.Default.Create(sstPath)
	if err != nil {
		return nil, errors.Trace(err)
	}
	writable := objstorageprovider.NewFileWritable(f)
	writer := rockssst.NewWriter(writable, rockssst.WriterOptions{
		// TODO(lance6716): should read TiKV config to know compression algorithm.
		Compression:  rocks.ZstdCompression,
		FilterPolicy: rocksbloom.FilterPolicy(10),
		MergerName:   "nullptr",
		TablePropertyCollectors: []func() rockssst.TablePropertyCollector{
			func() rockssst.TablePropertyCollector {
				return newMVCCPropCollector(ts)
			},
			func() rockssst.TablePropertyCollector {
				return newRangePropertiesCollector()
			},
			// TODO(lance6716): check if we should trigger titan
			func() rockssst.TablePropertyCollector {
				return mockCollector{name: "BlobFileSizeCollector"}
			},
		},
	}, identity)
	return &writeCFWriter{sstWriter: writer, ts: ts}, nil
}

// set mimic TiKV's `TxnSstWriter.put`. ref
// https://github.com/tikv/tikv/blob/7793f1d5dc40206fe406ca001be1e0d7f1b83a8f/components/sst_importer/src/sst_writer.rs#L92.
func (w *writeCFWriter) set(key, value []byte) error {
	intest.Assert(isShortValue(value), "not implemented, need to write to default CF")

	actualKey := make([]byte, 0, 1+len(key)+8)
	actualKey = append(actualKey, 'z')
	actualKey = codec.EncodeBytes(actualKey, key)
	actualKey = binary.BigEndian.AppendUint64(actualKey, ^w.ts)

	actualValue := make([]byte, 0, 1+binary.MaxVarintLen64+1+1+len(value))
	actualValue = append(actualValue, 'P')
	actualValue = binary.AppendUvarint(actualValue, w.ts)
	actualValue = append(actualValue, 'v')
	actualValue = append(actualValue, byte(len(value)))
	actualValue = append(actualValue, value...)

	return errors.Trace(w.sstWriter.Set(actualKey, actualValue))
}

func (w *writeCFWriter) close() error {
	return errors.Trace(w.sstWriter.Close())
}

func isShortValue(val []byte) bool {
	return len(val) <= 255
}
